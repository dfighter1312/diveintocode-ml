{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04bc0c0f",
   "metadata": {},
   "source": [
    "# Sprint 12\n",
    "\n",
    "# SimpleConv2d\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54d941f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eeeb57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInitializer:\n",
    "    \"\"\"\n",
    "    Simple initialization with Gaussian distribution\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      Standard deviation of Gaussian distribution\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma=0.01):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def W(self, *shape):\n",
    "        \"\"\"\n",
    "        Weight initialization\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          Number of nodes in the previous layer\n",
    "        n_nodes2 : int\n",
    "          Number of nodes in the later layer\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        W = self.sigma * np.random.randn(*shape)\n",
    "        return W\n",
    "    \n",
    "    def B(self, *shape):\n",
    "        \"\"\"\n",
    "        Bias initialization\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          Number of nodes in the later layer\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        B = self.sigma * np.random.randn(*shape)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "759d44e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeInitializer:\n",
    "    \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        self.sigma = np.sqrt(2 / n_nodes1)\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        B = self.sigma * np.random.randn(1, n_nodes2)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19a033ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInitializerConv2d:\n",
    "    \n",
    "    def __init__(self, sigma=0.01):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def W(self, F, C, FH, FW):\n",
    "        return self.sigma * np.random.randn(F, C, FH, FW)\n",
    "    \n",
    "    def B(self, F):\n",
    "        return np.zeros(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3c8ed91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"\n",
    "    Stochastic gradient descent\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : Learning rate\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        Update weights and biases for a layer\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : Instance of the layer before update\n",
    "        \"\"\"\n",
    "        layer.W -= self.lr * layer.dW\n",
    "        layer.B -= self.lr * layer.dB\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "774183dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "    \n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        self.HW = 0.0\n",
    "        self.HB = 0.0\n",
    "        \n",
    "    def update(self, layer):\n",
    "        self.HW += layer.dW * layer.dW\n",
    "        self.HB = layer.dB * layer.dB\n",
    "        delta = 1e-7\n",
    "        layer.W -= self.lr * layer.dW / (np.sqrt(self.HW) + delta)\n",
    "        layer.B -= self.lr * layer.dB / (np.sqrt(self.HB) + delta)\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4142851",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    \n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        Z = np.maximum(0, A)\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        dA = dZ * np.where(self.A > 0, 1, 0)\n",
    "        return dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6419960",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    \n",
    "    def forward(self, A):\n",
    "        self.Z = np.exp(A - np.max(A)) / np.sum(np.exp(A - np.max(A)), axis=1, keepdims=True)\n",
    "        return self.Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f9b35b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    Iterator to get a mini-batch\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : The following forms of ndarray, shape (n_samples, n_features)\n",
    "      Training data\n",
    "    y : The following form of ndarray, shape (n_samples, 1)\n",
    "      Correct answer value\n",
    "    batch_size : int\n",
    "      Batch size\n",
    "    seed : int\n",
    "      NumPy random number seed\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    \n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "    \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0a1f72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC:\n",
    "    \"\"\"\n",
    "    Number of nodes Fully connected layer from n_nodes1 to n_nodes2\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      Number of nodes in the previous layer\n",
    "    n_nodes2 : int\n",
    "      Number of nodes in the later layer\n",
    "    initializer: instance of initialization method\n",
    "    optimizer: instance of optimization method\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer, activation):\n",
    "        self.optimizer = optimizer\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.W = initializer.W(self.n_nodes1, self.n_nodes2)\n",
    "        self.B = initializer.B(self.n_nodes2)\n",
    "        self.optimizer = optimizer\n",
    "        self.activation = activation\n",
    "        pass\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        forward\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : The following forms of ndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : The following forms of ndarray, shape (batch_size, n_nodes2)\n",
    "            output\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.A = np.dot(self.X, self.W) + self.B\n",
    "        return self.activation.forward(self.A)\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        \"\"\"\n",
    "        Backward\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : The following forms of ndarray, shape (batch_size, n_nodes2)\n",
    "            Gradient flowing from behind\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : The following forms of ndarray, shape (batch_size, n_nodes1)\n",
    "            Gradient to flow forward\n",
    "        \"\"\"\n",
    "        dA = self.activation.backward(dZ)\n",
    "        self.dB = np.sum(dA, axis=0)\n",
    "        self.dW = np.dot(self.X.T, dA) / len(self.X)\n",
    "        self.dZ = np.dot(dA, self.W.T)\n",
    "        self = self.optimizer.update(self)\n",
    "        return self.dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f857c2",
   "metadata": {},
   "source": [
    "## Problem 1-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35d36fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConv2d():\n",
    "    \"\"\"\n",
    "    2D convolutional layer\n",
    "    Parameters\n",
    "    -------\n",
    "    F: Number of output channels\n",
    "    C: Number of input channels\n",
    "    FH: Filter's height.\n",
    "    FC: Filter's width.\n",
    "    P: Padding.\n",
    "    S: Stride.\n",
    "    initializer: Instances of initialization methods\n",
    "    optimizer: Instances of optimization methods\n",
    "    \"\"\"\n",
    "    def __init__(self, F, C, FH, FW, P=0, S=1, initializer=None, optimizer=None, activation=None):\n",
    "        # Create initializer\n",
    "        if isinstance(initializer, tuple) and len(initializer) == 2:\n",
    "            self.W = initializer[0]\n",
    "            self.B = initializer[1]\n",
    "        elif initializer is not None:\n",
    "            self.initializer = initializer\n",
    "            self.W = self.initializer.W(F, C, FH, FW)\n",
    "            self.B = self.initializer.B(F)\n",
    "        else:\n",
    "            raise TypeError('Need an initializer')\n",
    "        \n",
    "        if not isinstance(S, int) or S < 1:\n",
    "            raise ValueError('S must be an postive integer')\n",
    "        if not isinstance(P, int) or P < 0:\n",
    "            raise ValueError('P must be an non-negative integer')\n",
    "        self.P = P\n",
    "        self.S = S\n",
    "        self.F = F\n",
    "        self.C = C\n",
    "        self.FH = FH\n",
    "        self.FW = FW\n",
    "        \n",
    "        # Other setup\n",
    "        self.optimizer = optimizer\n",
    "        self.activation = activation\n",
    "        \n",
    "    def output_shape(self, H, W, P, FH, FW, S):\n",
    "        OH = (H + 2*P - FH) / S + 1\n",
    "        OW = (W + 2*P - FW) / S + 1\n",
    "        return int(OH), int(OW)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Forward method.\n",
    "        Parameters\n",
    "        -------\n",
    "        X: ndarray\n",
    "            Input data\n",
    "        Returns\n",
    "        -------\n",
    "        A: ndarray\n",
    "            Output data\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.N, C, self.H, self.WD = self.X.shape\n",
    "        \n",
    "        if C != self.C:\n",
    "            raise ValueError(f'Incorrect shape of X, expected {self.C}, but got {C}')\n",
    "            \n",
    "        self.OH, self.OW = self.output_shape(self.H, self.WD, self.P, self.FH, self.FW, self.S)\n",
    "        \n",
    "        A = np.zeros([self.N, self.F, self.OH, self.OW])\n",
    "        self.X_pad = np.pad(\n",
    "            self.X,\n",
    "            ((0,0), (0,0), (self.P, self.P), (self.P, self.P))\n",
    "        )\n",
    "\n",
    "        for n in range(self.N):\n",
    "            for ch in range(self.F):\n",
    "                for row in range(0, self.OH, self.S):\n",
    "                    for col in range(0, self.OW, self.S):\n",
    "                        A[n, ch, row, col] = np.sum(self.X_pad[n, :, row:row+self.FH, col:col+self.FW] \\\n",
    "                                             * self.W[ch, :, :, :]) + self.B[ch]\n",
    "        if self.activation is None:\n",
    "            return A\n",
    "        return self.activation.forward(A)\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        \"\"\"\n",
    "        Backward method.\n",
    "        Parameters\n",
    "        -------\n",
    "        dZ: \n",
    "            The gradient flown in from behind.\n",
    "        Returns\n",
    "        -------\n",
    "        dZ: ndarray\n",
    "            Forward slope\n",
    "        \"\"\"\n",
    "        if self.activation is None:\n",
    "            dA = dZ\n",
    "        else:\n",
    "            dA = self.activation.backward(dZ)\n",
    "        \n",
    "        dZ = np.zeros(self.X_pad.shape)\n",
    "        self.dW = np.zeros(self.W.shape)\n",
    "        self.dB = np.zeros(self.B.shape)\n",
    "        \n",
    "        for n in range(self.N):\n",
    "            for ch in range(self.F):\n",
    "                for row in range(0, self.OH, self.S):\n",
    "                    for col in range(0, self.OW, self.S):\n",
    "                        dZ[n, :, row:row+self.FH, col:col+self.FW] += dA[n, ch, row, col] * self.W[ch, :, :, :]\n",
    "                        \n",
    "        dl_rows = range(self.P), range(self.H + self.P, self.H + 2*self.P, 1)\n",
    "        dl_cols = range(self.P), range(self.WD + self.P, self.WD + 2*self.P, 1)\n",
    "        \n",
    "        dZ = np.delete(dZ, dl_rows, axis=2)\n",
    "        dZ = np.delete(dZ, dl_cols, axis=3)\n",
    "        \n",
    "        for n in range(self.N):\n",
    "            for ch in range(self.F):\n",
    "                for row in range(self.OH):\n",
    "                    for col in range(self.OW):\n",
    "                        self.dW[ch, :, :, :] += dA[n, ch, row, col] * self.X_pad[n, :, row:row+self.FH, col:col+self.FW]\n",
    "                        \n",
    "        for ch in range(self.F):\n",
    "            self.dB[ch] = np.sum(dA[:, ch, :, :])\n",
    "        \n",
    "        # Update\n",
    "        if self.optimizer is not None:\n",
    "            self = self.optimizer.update(self)\n",
    "        \n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "002d21de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1,1,4,4)\n",
    "x = np.array([[[[ 1,  2,  3,  4],\n",
    "                [ 5,  6,  7,  8],\n",
    "                [ 9, 10, 11, 12],\n",
    "                [13, 14, 15, 16]]]])\n",
    "# (2,1,3,3)\n",
    "w = np.array([[[[ 0.,  0.,  0.],\n",
    "               [ 0.,  1.,  0.],\n",
    "               [ 0., -1.,  0.]]],\n",
    "              [[[ 0.,  0.,  0.],\n",
    "               [ 0., -1.,  1.],\n",
    "               [ 0.,  0.,  0.]]]])\n",
    "\n",
    "b = np.array([0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "beb7d7e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-4., -4.],\n",
       "         [-4., -4.]],\n",
       "\n",
       "        [[ 1.,  1.],\n",
       "         [ 1.,  1.]]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = SimpleConv2d(2, 1, 3, 3, initializer=(w, b))\n",
    "result = test1.forward(x)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97391eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[  0.,   0.,   0.,   0.],\n",
       "         [  0.,  -5.,   4.,  -7.],\n",
       "         [  0.,  13.,  27., -11.],\n",
       "         [  0., -10., -11.,   0.]]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dZ = np.array([[[[ -4,  -4],\n",
    "                   [ 10,  11]],\n",
    "                  [[  1,  -7],\n",
    "                   [  1, -11]]]])\n",
    "\n",
    "back_result = test1.backward(dZ)\n",
    "back_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eddc76ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 4, 28, 28)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2 = SimpleConv2d(4, 1, 3, 3, P=1, initializer=(np.ones([4, 1, 3, 3]), np.ones(4)))\n",
    "result2 = test2.forward(np.ones([5, 1, 28, 28]))\n",
    "result2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18d0d030",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 1, 28, 28), (4, 1, 3, 3), (4,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "back_result2 = test2.backward(np.zeros([5, 4, 28, 28]))\n",
    "back_result2.shape, test2.dW.shape, test2.dB.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dff92a7",
   "metadata": {},
   "source": [
    "## [Problem 5] (Advance task) Creating average pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3912fd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2D():\n",
    "    \n",
    "    def __init__(self, P):\n",
    "        self.P = P\n",
    "        self.PA = None\n",
    "        self.Pidx = None\n",
    "        \n",
    "    def forward(self, A):\n",
    "        N, F, OH, OW = A.shape\n",
    "        PS = self.P\n",
    "        PH, PW = int(OH/PS), int(OW/PS)\n",
    "        \n",
    "        self.params = N, F, OH, OW, PS, PH, PW\n",
    "        \n",
    "        # Pooling filter\n",
    "        self.PA = np.zeros((N, F, PH, PW))\n",
    "        self.Pidx = np.zeros((N, F, PH, PW))\n",
    "        \n",
    "        for n in range(N):\n",
    "            for ch in range(F):\n",
    "                for row in range(PH):\n",
    "                    for col in range(PW):\n",
    "                        self.PA[n, ch, row, col] = np.max(A[n, ch, row*PS:row*PS+PS, col*PS:col*PS+PS])\n",
    "                        self.Pidx[n, ch, row, col] = np.argmax(A[n, ch, row*PS:row*PS+PS, col*PS:col*PS+PS])\n",
    "        return self.PA\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        N, F, OH, OW, PS, PH, PW = self.params\n",
    "        dP = np.zeros((N, F, OH, OW))\n",
    "        \n",
    "        for n in range(N):\n",
    "            for ch in range(F):\n",
    "                for row in range(PH):\n",
    "                    for col in range(PW):\n",
    "                        idx = self.Pidx[n, ch, row, col]\n",
    "                        tmp = np.zeros((PS*PS))\n",
    "                        for i in range(PS*PS):\n",
    "                            if i == idx:\n",
    "                                tmp[i] = dA[n, ch, row, col]\n",
    "                            else:\n",
    "                                tmp[i] = 0\n",
    "                        dP[n, ch, row*PS:row*PS+PS, col*PS:col*PS+PS] = tmp.reshape(PS, PS)\n",
    "        return dP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "231d88be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 6, 6)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[[\n",
    "    [3, 6, 0, 3, 1, 0],\n",
    "    [6, 8, 3, 4, 1, 0],\n",
    "    [7, 8, 6, 6, 8, 2],\n",
    "    [7, 6, 4, 4, 0, 2],\n",
    "    [0, 6, 6, 1, 5, 7],\n",
    "    [0, 5, 5, 4, 7, 7]\n",
    "]]])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c084875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[8., 4., 1.],\n",
       "         [8., 6., 8.],\n",
       "         [6., 6., 7.]]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooling = MaxPool2D(P=2)\n",
    "A = pooling.forward(X)\n",
    "\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13c247b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[3., 3., 0.],\n",
       "         [1., 0., 0.],\n",
       "         [1., 0., 1.]]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooling.Pidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f3c5bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dA = A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78791033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0., 0., 0., 0., 1., 0.],\n",
       "         [0., 8., 0., 4., 0., 0.],\n",
       "         [0., 8., 6., 0., 8., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 6., 6., 0., 0., 7.],\n",
       "         [0., 0., 0., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dZ = pooling.backward(dA)\n",
    "dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cd1f6d",
   "metadata": {},
   "source": [
    "## [Problem 5] Create Average Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18d87aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragePool2D():\n",
    "    \n",
    "    def __init__(self, P):\n",
    "        self.P = P\n",
    "        self.PA = None\n",
    "        self.Pidx = None\n",
    "        \n",
    "    def forward(self, A):\n",
    "        N, F, OH, OW = A.shape\n",
    "        PS = self.P\n",
    "        PH, PW = int(OH/PS), int(OW/PS)\n",
    "        \n",
    "        self.params = N, F, OH, OW, PS, PH, PW\n",
    "        \n",
    "        # Pooling filter\n",
    "        self.PA = np.zeros((N, F, PH, PW))\n",
    "        self.Pidx = np.zeros((N, F, PH, PW))\n",
    "        \n",
    "        for n in range(N):\n",
    "            for ch in range(F):\n",
    "                for row in range(PH):\n",
    "                    for col in range(PW):\n",
    "                        self.PA[n, ch, row, col] = np.mean(A[n, ch, row*PS:row*PS+PS, col*PS:col*PS+PS])\n",
    "                        \n",
    "        return self.PA\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        N, F, OH, OW, PS, PH, PW = self.params\n",
    "        dP = np.zeros((N, F, OH, OW))\n",
    "        \n",
    "        for n in range(N):\n",
    "            for ch in range(F):\n",
    "                for row in range(PH):\n",
    "                    for col in range(PW):\n",
    "                        tmp = np.zeros((PS*PS))\n",
    "                        for i in range(PS*PS):\n",
    "                            tmp[i] = dA[n, ch, row, col] / (PS*PS)\n",
    "                        dP[n, ch, row*PS:row*PS+PS, col*PS:col*PS+PS] = tmp.reshape(PS, PS)\n",
    "        return dP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a6a41e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[[\n",
    "    [2, 1, 2, 3, 0, 2],\n",
    "    [4, 4, 8, 8, 8, 0],\n",
    "    [5, 8, 0, 8, 7, 0],\n",
    "    [8, 3, 0, 0, 0, 5],\n",
    "    [0, 8, 3, 0, 5, 7],\n",
    "    [4, 8, 3, 6, 7, 6]\n",
    "]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbf45222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[2.75, 5.25, 2.5 ],\n",
       "         [6.  , 2.  , 3.  ],\n",
       "         [5.  , 3.  , 6.25]]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooling = AveragePool2D(P=2)\n",
    "A = pooling.forward(X)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "497b3683",
   "metadata": {},
   "outputs": [],
   "source": [
    "dA = np.array([[[\n",
    "    [2, 6, 6],\n",
    "    [6, 5, 3],\n",
    "    [3, 6, 5]\n",
    "]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f323af04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.5 , 0.5 , 1.5 , 1.5 , 1.5 , 1.5 ],\n",
       "         [0.5 , 0.5 , 1.5 , 1.5 , 1.5 , 1.5 ],\n",
       "         [1.5 , 1.5 , 1.25, 1.25, 0.75, 0.75],\n",
       "         [1.5 , 1.5 , 1.25, 1.25, 0.75, 0.75],\n",
       "         [0.75, 0.75, 1.5 , 1.5 , 1.25, 1.25],\n",
       "         [0.75, 0.75, 1.5 , 1.5 , 1.25, 1.25]]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dZ = pooling.backward(dA)\n",
    "dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf517be0",
   "metadata": {},
   "source": [
    "## [Problem 6] Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e53486da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten():\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.shape = X.shape\n",
    "        return X.reshape(len(X), -1)\n",
    "    \n",
    "    def backward(self, X):\n",
    "        return X.reshape(self.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2d9fe5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 30000)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.zeros((10, 20, 30, 50))\n",
    "flat = Flatten()\n",
    "flat_forward = flat.forward(X)\n",
    "flat_forward.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "805ebe19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 20, 30, 50)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat.backward(flat_forward).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c31bbb",
   "metadata": {},
   "source": [
    "## [Problem 7] Learning and estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "547b15df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class Scratch2dCNNClassifier():\n",
    "    \n",
    "    def __init__(self, NN, CNN, n_epoch=5, n_batch=1, verbose=False):\n",
    "        self.NN = NN\n",
    "        self.CNN = CNN\n",
    "        self.n_epoch = n_epoch\n",
    "        self.n_batch = n_batch\n",
    "        self.verbose = verbose\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.accs = []\n",
    "        self.val_accs = []\n",
    "        \n",
    "    def loss_function(self, y, yt):\n",
    "        delta = 1e-7\n",
    "        return -np.mean(yt*np.log(y+delta))\n",
    "    \n",
    "    def accuracy(self, Z, Y):\n",
    "        return accuracy_score(Y, Z)\n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        Train a neural network classifier.\n",
    "        \n",
    "        Parameters:\n",
    "        -------\n",
    "        X: ndarray\n",
    "            Training data.\n",
    "        y: ndarray\n",
    "            Target values of training data.\n",
    "        X_val: ndarray\n",
    "            Validation data.\n",
    "        y_val: ndarray\n",
    "            Target values of validation data.\n",
    "        \"\"\"\n",
    "        for epoch in range(self.n_epoch):\n",
    "            print(f\"Epoch {epoch+1}\")\n",
    "            self.loss = 0\n",
    "            self.val_loss = 0\n",
    "            \n",
    "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.n_batch)\n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "                \n",
    "                # Forward\n",
    "                forward_data = mini_X_train[:, np.newaxis, :, :]\n",
    "                \n",
    "                for layer in range(len(self.CNN)):\n",
    "                    forward_data = self.CNN[layer].forward(forward_data)\n",
    "                \n",
    "                # Flatten\n",
    "                fit = Flatten()\n",
    "                forward_data = fit.forward(forward_data)\n",
    "                \n",
    "                # NN\n",
    "                for layer in range(len(self.NN)):\n",
    "                    forward_data = self.NN[layer].forward(forward_data)\n",
    "                \n",
    "                Z = forward_data\n",
    "                \n",
    "                # Backward\n",
    "                backward_data = (Z - mini_y_train)/self.n_batch\n",
    "                for layer in range(len(self.NN)-1, -1, -1):\n",
    "                    backward_data = self.NN[layer].backward(backward_data)\n",
    "                    \n",
    "                backward_data = fit.backward(backward_data)\n",
    "                \n",
    "                for layer in range(len(self.CNN)-1, -1, -1):\n",
    "                    backward_data = self.CNN[layer].backward(backward_data)\n",
    "                \n",
    "                self.loss += self.loss_function(Z, mini_y_train)\n",
    "            \n",
    "            loss = self.loss/len(get_mini_batch)\n",
    "            acc = self.accuracy(self.predict(X), np.argmax(y, axis=1))\n",
    "            print(f\"loss: {loss}, acc: {acc}\")\n",
    "            self.losses.append(loss)\n",
    "#             self.val_losses.append(self.val_loss/len(get_mini_batch))\n",
    "            self.accs.append(acc)\n",
    "#             if X_val is not None and y_val is not None:\n",
    "#                 self.val_accs.append(self.accuracy(self.predict(X_val), np.argmax(y_val, axis=1)))\n",
    "            \n",
    "    def predict(self, X):\n",
    "        pred_data = X[:, np.newaxis, :, :]\n",
    "        \n",
    "        for layer in range(len(self.CNN)):\n",
    "            pred_data = self.CNN[layer].forward(pred_data)\n",
    "            \n",
    "        fit = Flatten()\n",
    "        pred_data = fit.forward(pred_data)\n",
    "        \n",
    "        for layer in range(len(self.NN)):\n",
    "            pred_data = self.NN[layer].forward(pred_data)\n",
    "        \n",
    "        return np.argmax(pred_data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f6e128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = [\n",
    "    FC(3136, 128, HeInitializer(), AdaGrad(0.01), ReLU()),\n",
    "    FC(128, 10, SimpleInitializer(0.01), AdaGrad(0.01), Softmax()),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7bc30809",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN = [\n",
    "    SimpleConv2d(F=32, C=1, FH=3, FW=3, P=1, S=1,\n",
    "                 initializer=SimpleInitializerConv2d(),\n",
    "                 optimizer=SGD(0.01),\n",
    "                 activation=ReLU()),\n",
    "    MaxPool2D(P=2),\n",
    "    SimpleConv2d(F=64, C=32, FH=3, FW=3, P=1, S=1,\n",
    "                 initializer=SimpleInitializerConv2d(),\n",
    "                 optimizer=SGD(0.01),\n",
    "                 activation=ReLU()),\n",
    "    MaxPool2D(P=2),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ef0543b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 28, 28)\n",
      "(48000,)\n",
      "(12000, 28, 28)\n",
      "(12000,)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d099922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 10)\n",
      "(12000, 10)\n"
     ]
    }
   ],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_val_one_hot = enc.transform(y_val[:, np.newaxis])\n",
    "\n",
    "print(y_train_one_hot.shape)\n",
    "print(y_val_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "64db02b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "loss: 0.22950013024572483, acc: 0.16\n",
      "Epoch 2\n",
      "loss: 0.2251226749303142, acc: 0.16\n",
      "Epoch 3\n",
      "loss: 0.215636658340688, acc: 0.16\n",
      "Epoch 4\n",
      "loss: 0.1954295979616378, acc: 0.37\n",
      "Epoch 5\n",
      "loss: 0.1580466495240975, acc: 0.64\n",
      "Epoch 6\n",
      "loss: 0.11698675633267004, acc: 0.77\n",
      "Epoch 7\n",
      "loss: 0.09042039109930419, acc: 0.785\n",
      "Epoch 8\n",
      "loss: 0.07553508714050092, acc: 0.815\n",
      "Epoch 9\n",
      "loss: 0.06400469326073029, acc: 0.85\n",
      "Epoch 10\n",
      "loss: 0.0553971352093953, acc: 0.87\n",
      "Epoch 11\n",
      "loss: 0.04835099728033258, acc: 0.885\n",
      "Epoch 12\n",
      "loss: 0.04266954635867636, acc: 0.895\n",
      "Epoch 13\n",
      "loss: 0.03812310199685194, acc: 0.905\n",
      "Epoch 14\n",
      "loss: 0.03416317354749439, acc: 0.91\n",
      "Epoch 15\n",
      "loss: 0.030720370398249448, acc: 0.91\n",
      "Epoch 16\n",
      "loss: 0.027783107208955347, acc: 0.93\n",
      "Epoch 17\n",
      "loss: 0.02542399153124229, acc: 0.94\n",
      "Epoch 18\n",
      "loss: 0.023230329343883645, acc: 0.945\n",
      "Epoch 19\n",
      "loss: 0.021341827995763327, acc: 0.945\n",
      "Epoch 20\n",
      "loss: 0.01953093716664969, acc: 0.945\n"
     ]
    }
   ],
   "source": [
    "cnn1 = Scratch2dCNNClassifier(NN=NN, CNN=CNN, n_epoch=20, n_batch=20, verbose=False)\n",
    "\n",
    "cnn1.fit(X_train[:200], y_train_one_hot[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f55fa5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 9 8 3 7 2 7 3 9 5 7 0 2 7 5 6 4 9 5 2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        21\n",
      "           1       1.00      1.00      1.00        17\n",
      "           2       1.00      0.91      0.95        32\n",
      "           3       0.95      1.00      0.98        21\n",
      "           4       0.88      0.82      0.85        17\n",
      "           5       1.00      1.00      1.00        24\n",
      "           6       0.95      1.00      0.97        18\n",
      "           7       0.93      0.88      0.90        16\n",
      "           8       0.95      1.00      0.98        20\n",
      "           9       0.69      0.79      0.73        14\n",
      "\n",
      "    accuracy                           0.94       200\n",
      "   macro avg       0.94      0.94      0.94       200\n",
      "weighted avg       0.95      0.94      0.95       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = cnn1.predict(X_train[:200])\n",
    "print(y_train_pred[:20])\n",
    "print(classification_report(y_train[:200], y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d435a781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 9 4 7 9 3 9 7 7 8 9 1 5 5 1 3 7 3 9]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        18\n",
      "           1       0.95      0.78      0.86        23\n",
      "           2       0.81      0.88      0.85        25\n",
      "           3       0.78      0.90      0.84        20\n",
      "           4       0.61      0.71      0.65        24\n",
      "           5       0.63      0.80      0.71        15\n",
      "           6       0.92      0.80      0.86        15\n",
      "           7       0.84      0.84      0.84        19\n",
      "           8       0.80      0.57      0.67        21\n",
      "           9       0.55      0.55      0.55        20\n",
      "\n",
      "    accuracy                           0.78       200\n",
      "   macro avg       0.79      0.78      0.78       200\n",
      "weighted avg       0.79      0.78      0.78       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = cnn1.predict(X_val[:200])\n",
    "print(y_val_pred[:20])\n",
    "print(classification_report(y_val[:200], y_val_pred[:200]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d628b2eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(np.arange(1, cnn1.n_epoch+1), cnn1.losses, label='train_loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(np.arange(1, cnn1.n_epoch+1), cnn1.accs, label='train_acc')\n",
    "plt.xlabel('Epochs')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a82fdd1",
   "metadata": {},
   "source": [
    "## [Problem 10] Calculation of output size and number of parameters\n",
    "\n",
    "1.\n",
    "- Input size : 144 x 144, 3 channels\n",
    "- Filter size: 3 x 3, 6 channels\n",
    "- Stride : 1\n",
    "- Padding: none\n",
    "\n",
    "OH = OW = (144 + 2 x 0 - 3) / 1 + 1 = 142\n",
    "\n",
    "Output size: (6, 142, 142)\n",
    "\n",
    "Parameters:\n",
    "- Weight shape: (6, 3, 3, 3) => 162 parameters\n",
    "- Bias shape: (6, ) => 6 parameters\n",
    "\n",
    "Total: 168 parameters\n",
    "\n",
    "2.\n",
    "- Input size : 60x60, 24 channels\n",
    "- Filter size: 3 x 3, 48 channels\n",
    "- Stride : 1\n",
    "- Padding: none\n",
    "\n",
    "OH = OW = (60 + 2 x 0 - 3) / 1 + 1 = 58\n",
    "\n",
    "Output size: (48, 58, 58)\n",
    "\n",
    "Parameters:\n",
    "- Weight shape: (48, 24, 3, 3) => 10368 parameters\n",
    "- Bias shape: (48, ) => 48 parameters\n",
    "\n",
    "Total: 10416 parameters\n",
    "\n",
    "3.\n",
    "- Input size : 20 x 20, 10 channels\n",
    "- Filter size: 3 x 3, 20 channels\n",
    "- Stride: 2\n",
    "- Padding: none\n",
    "\n",
    "OH = OW = (20 + 2 x 0 - 3) / 2 + 1 = 9.5\n",
    "\n",
    "Output: (20, 9, 9)\n",
    "\n",
    "Parameters:\n",
    "- Weight shape: (20, 10, 3, 3) => 1800 parameters\n",
    "- Bias shape: (20, ) => 20 parameters\n",
    "\n",
    "Total: 1820 parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4522df3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
