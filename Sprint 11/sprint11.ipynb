{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4dbe3c7",
   "metadata": {},
   "source": [
    "# Sprint 11\n",
    "\n",
    "## SimpleConv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f24a38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3882cc",
   "metadata": {},
   "source": [
    "## [Problem 1] Creating a one-dimensional convolutional layer class that limits the number of channels to one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb6ddc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConv1d():\n",
    "    \n",
    "    def forward(self, x, w, b):\n",
    "        a = np.empty((len(w) - 1))\n",
    "        for i in range(a.shape[0]):\n",
    "            a[i] = (x[i:i + len(w)] @ w) + b[0]\n",
    "        return a\n",
    "    \n",
    "    def backward(self, x, w, da):\n",
    "        db = np.sum(da)\n",
    "        \n",
    "        dw = np.empty((len(w)))\n",
    "        for i in range(dw.shape[0]):\n",
    "            dw[i] = da @ x[i:i + len(da)]\n",
    "        \n",
    "        \n",
    "        new_w = np.insert(w[::-1], 0, 0)\n",
    "        new_w = np.append(new_w, 0)\n",
    "        dx = np.empty((len(new_w) - 1))\n",
    "        for i in range(dx.shape[0]):\n",
    "            dx[i] = new_w[i:i + len(da)] @ da\n",
    "        dx = dx[::-1]\n",
    "        return db, dw, dx\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7591df30",
   "metadata": {},
   "source": [
    "## [Problem 2] Output size calculation after one-dimensional convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c402da47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_size_calculation(n_in, P, F, S):\n",
    "    n_out = int((n_in + 2*P - F) / S + 1)\n",
    "    return n_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd032aaa",
   "metadata": {},
   "source": [
    "## [Problem 3] Experiment of one-dimensional convolutional layer with small array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99676490",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3, 4])\n",
    "w = np.array([3, 5, 7])\n",
    "b = np.array([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f4d9a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35. 50.]\n"
     ]
    }
   ],
   "source": [
    "sc1d = SimpleConv1d()\n",
    "a = sc1d.forward(x, w, b)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac1b6ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_a = np.array([10, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbe27a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 [ 50.  80. 110.] [ 30. 110. 170. 140.]\n"
     ]
    }
   ],
   "source": [
    "delta_b, delta_w, delta_x = sc1d.backward(x, w, delta_a)\n",
    "print(delta_b, delta_w, delta_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00b8d9f",
   "metadata": {},
   "source": [
    "## [Problem 4-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57f38699",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInitializer:\n",
    "    \"\"\"\n",
    "    Simple initialization with Gaussian distribution\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      Standard deviation of Gaussian distribution\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def W(self, *shape):\n",
    "        \"\"\"\n",
    "        Weight initialization\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          Number of nodes in the previous layer\n",
    "        n_nodes2 : int\n",
    "          Number of nodes in the later layer\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        W = self.sigma * np.random.randn(*shape)\n",
    "        return W\n",
    "    \n",
    "    def B(self, *shape):\n",
    "        \"\"\"\n",
    "        Bias initialization\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          Number of nodes in the later layer\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        B = self.sigma * np.random.randn(*shape)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b101e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"\n",
    "    Stochastic gradient descent\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : Learning rate\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        Update weights and biases for a layer\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : Instance of the layer before update\n",
    "        \"\"\"\n",
    "        layer.W -= self.lr * layer.dW\n",
    "        layer.B -= self.lr * layer.dB\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32eca881",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1d:\n",
    "    \n",
    "    def __init__(self, b_size, initializer, optimizer, n_in_channels=1, n_out_channels=1, pa=0, s=1):\n",
    "        self.b_size = b_size\n",
    "        self.optimizer = optimizer\n",
    "        self.n_in_channels = n_in_channels\n",
    "        self.n_out_channels = n_out_channels\n",
    "        self.pa = pa\n",
    "        self.s = s\n",
    "        self.W = initializer.W(n_out_channels, n_in_channels, b_size)\n",
    "        self.B = initializer.B(n_out_channels)\n",
    "        self.n_out = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.n_in = X.shape[-1]\n",
    "        self.n_out = output_size_calculation(self.n_in, self.pa, self.b_size, self.s)\n",
    "        X = X.reshape(self.n_in_channels, self.n_in)\n",
    "        self.X = np.pad(X, ((0, 0), ((self.b_size - 1), 0)))\n",
    "        self.X1 = np.zeros((self.n_in_channels, self.b_size, self.n_in + (self.b_size - 1)))\n",
    "        for i in range(self.b_size):\n",
    "            self.X1[:, i] = np.roll(self.X, -i, axis=-1)\n",
    "        A = np.sum(self.X1[:, :, (self.b_size - 1 - self.pa):(self.n_in + self.pa)] * self.W[:, :, :, np.newaxis], axis=(1, 2)) + self.B.reshape(-1, 1)\n",
    "        return A\n",
    "\n",
    "    def backward(self, dA):\n",
    "        self.dW = np.sum(np.dot(dA, self.X1[:, :, (self.b_size - 1 - self.pa):(self.n_in + self.pa), np.newaxis]), axis=-1)\n",
    "        self.dB = np.sum(dA, axis=1)\n",
    "        self.dA = np.pad(dA, ((0, 0), (0, (self.b_size - 1))))\n",
    "        self.dA1 = np.zeros((self.n_out_channels, self.b_size, self.dA.shape[-1]))\n",
    "        for i in range(self.b_size):\n",
    "            self.dA1[:, i] = np.roll(self.dA, i, axis=-1)\n",
    "        dX = np.sum(self.W @ self.dA1, axis=0)\n",
    "        self.optimizer.update(self)\n",
    "        return dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d576b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1d = Conv1d(b_size=3, initializer=SimpleInitializer(0.01), optimizer=SGD(0.01), n_in_channels=2, n_out_channels=3, pa=0, s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4da62cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]]) #shape (2, 4), (number of input channels, number of features).\n",
    "c1d.W = np.ones((3, 2, 3)) # Set to 1 for simplification of the example. (Number of output channels, number of input channels, filter size).\n",
    "c1d.B = np.array([1, 2, 3]) # (Number of output channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d631f348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16., 22.],\n",
       "       [17., 23.],\n",
       "       [18., 24.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = c1d.forward(x)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64695bc7",
   "metadata": {},
   "source": [
    "## [Problem 7] (Advance assignment) Arbitrary number of strides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "997114ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1dWithStride:\n",
    "    \n",
    "    def __init__(self, b_size, initializer, optimizer, n_in_channels=1, n_out_channels=1, pa=0, s=1):\n",
    "        self.b_size = b_size\n",
    "        self.optimizer = optimizer\n",
    "        self.n_in_channels = n_in_channels\n",
    "        self.n_out_channels = n_out_channels\n",
    "        self.pa = pa\n",
    "        self.s = s\n",
    "        self.W = initializer.W(n_out_channels, n_in_channels, b_size)\n",
    "        self.B = initializer.B(n_out_channels)\n",
    "        self.n_out = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.n_samples = X.shape[0]\n",
    "        self.n_in = X.shape[-1]\n",
    "        self.n_out = output_size_calculation(self.n_in, self.pa, self.b_size, self.s)\n",
    "        X = X.reshape(self.n_samples, self.n_in_channels, self.n_in)\n",
    "        self.X = np.pad(X, ((0, 0), (0, 0), ((self.b_size - 1), 0)))\n",
    "        self.X1 = np.zeros((self.n_samples, self.n_in_channels, self.b_size, self.n_in + (self.b_size - 1)))\n",
    "        for i in range(self.b_size):\n",
    "            self.X1[:, :, i] = np.roll(self.X, -i, axis=-1)\n",
    "        A = np.sum(self.X1[:, np.newaxis, :, :, (self.b_size - 1 - self.pa):(self.n_in + self.pa):self.s] * self.W[:, :, :, np.newaxis], axis=(2, 3)) + self.B.reshape(-1, 1)\n",
    "        return A\n",
    "\n",
    "    def backward(self, dA):\n",
    "        self.dW = np.sum(dA[:, :, np.newaxis, np.newaxis] * self.X1[:, np.newaxis, :, :, (self.b_size - 1 - self.pa):(self.n_in + self.pa):self.s], axis=(0, -1))\n",
    "        self.dB = np.sum(dA, axis=(0, -1))\n",
    "        self.dA = np.pad(dA, ((0, 0), (0, 0), (0, (self.b_size - 1))))\n",
    "        self.dA1 = np.zeros((self.n_samples, self.n_out_channels, self.b_size, self.dA.shape[-1]))\n",
    "        for i in range(self.b_size):\n",
    "            self.dA1[:, :, i] = np.roll(self.dA, i, axis=-1)\n",
    "        dX = np.sum(self.W[:, :, :, np.newaxis] * self.dA1[:, :, np.newaxis], axis=(1, 3))\n",
    "        self.optimizer.update(self)\n",
    "        return dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86b95b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1ds = Conv1dWithStride(b_size=3, initializer=SimpleInitializer(0.01), optimizer=SGD(0.01), n_in_channels=2, n_out_channels=3, pa=0, s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88a02b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[[1, 2, 3, 4], [2, 3, 4, 5]]]) #shape (2, 4), (number of input channels, number of features).\n",
    "c1ds.W = np.ones((3, 2, 3)) # Set to 1 for simplification of the example. (Number of output channels, number of input channels, filter size).\n",
    "c1ds.B = np.array([1, 2, 3]) # (Number of output channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd539f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[16., 22.],\n",
       "        [17., 23.],\n",
       "        [18., 24.]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = c1ds.forward(x)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98de445c",
   "metadata": {},
   "source": [
    "## [Problem 8] Learning and estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20fba03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC:\n",
    "    \"\"\"\n",
    "    Number of nodes Fully connected layer from n_nodes1 to n_nodes2\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      Number of nodes in the previous layer\n",
    "    n_nodes2 : int\n",
    "      Number of nodes in the later layer\n",
    "    initializer: instance of initialization method\n",
    "    optimizer: instance of optimization method\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.W = initializer.W(self.n_nodes1, self.n_nodes2)\n",
    "        self.B = initializer.B(self.n_nodes2)\n",
    "        self.optimizer = optimizer\n",
    "        self.HW = 0\n",
    "        self.HB = 0\n",
    "        pass\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        forward\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : The following forms of ndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : The following forms of ndarray, shape (batch_size, n_nodes2)\n",
    "            output\n",
    "        \"\"\"       \n",
    "        self.Z = X\n",
    "        self.A = X @ self.W + self.B\n",
    "        return self.A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        Backward\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : The following forms of ndarray, shape (batch_size, n_nodes2)\n",
    "            Gradient flowing from behind\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : The following forms of ndarray, shape (batch_size, n_nodes1)\n",
    "            Gradient to flow forward\n",
    "        \"\"\"\n",
    "        self.dB = np.sum(dA, axis=0)\n",
    "        self.dW = self.Z.T @ dA\n",
    "        self.dZ = dA @ self.W.T\n",
    "        self = self.optimizer.update(self)\n",
    "        return self.dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1e90d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    Iterator to get a mini-batch\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : The following forms of ndarray, shape (n_samples, n_features)\n",
    "      Training data\n",
    "    y : The following form of ndarray, shape (n_samples, 1)\n",
    "      Correct answer value\n",
    "    batch_size : int\n",
    "      Batch size\n",
    "    seed : int\n",
    "      NumPy random number seed\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    \n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "    \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74d43d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    \n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        Z = 1 / (1 + np.exp(-self.A))\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        dA = dZ * ((1 / (1 + np.exp(-self.A))) - (1 / (1 + np.exp(-self.A))) ** 2)\n",
    "        return dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79a90f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh:\n",
    "    \n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        Z = np.tanh(self.A)\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        dA = dZ + (1 - np.tanh(self.A) ** 2)\n",
    "        return dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a4b7801",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    \n",
    "    def forward(self, A):\n",
    "        self.Z = np.exp(A) / np.sum(np.exp(A), axis=1).reshape(-1, 1)\n",
    "        return self.Z\n",
    "    \n",
    "    def backward(self, y, Z=None):\n",
    "        if Z is None:\n",
    "            Z = self.Z\n",
    "        dA = Z - y\n",
    "        loss = -np.average(np.sum(y * np.log(Z), axis=1))\n",
    "        return dA, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e90748e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    \n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        Z = np.maximum(0, A)\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        dA = dZ * np.where(self.A > 0, 1, 0)\n",
    "        return dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68038b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XavierInitializer:\n",
    "    \n",
    "    def __init__(self, sigma):\n",
    "        pass\n",
    "    \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        self.sigma = 1 / np.sqrt(n_nodes1)\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        B = self.sigma * np.random.randn(1, n_nodes2)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9214576",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeInitializer:\n",
    "    \n",
    "    def __init__(self, sigma):\n",
    "        pass\n",
    "    \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        self.sigma = np.sqrt(2 / n_nodes1)\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        B = self.sigma * np.random.randn(1, n_nodes2)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc7e8746",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "    \n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        self.HW = 1\n",
    "        self.HB = 1\n",
    "        \n",
    "    def update(self, layer):\n",
    "        self.HW += layer.dW ** 2\n",
    "        self.HB += layer.dB ** 2\n",
    "        layer.W -= self.lr * np.sqrt(1 / self.HW) * layer.dW\n",
    "        layer.B -= self.lr * np.sqrt(1 / self.HB) * layer.dB\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3962a665",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchCNNClassifier():\n",
    "    \"\"\"\n",
    "    Simple three-layer CNN classifier\n",
    "    Parameters\n",
    "    ----------\n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma=0.01, n_features=784, n_nodes1=400, n_nodes2=200,\n",
    "                 n_output=10, learning_rate=0.01, epochs=10, \n",
    "                 batch_size=32, verbose=True, optimizer=SGD,\n",
    "                 activater=ReLU):\n",
    "        self.verbose = verbose\n",
    "        self.sigma = sigma\n",
    "        self.n_features = n_features\n",
    "#         self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.n_output = n_output\n",
    "        self.lr = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Update\n",
    "        self.optimizer = optimizer\n",
    "        self.activater = activater\n",
    "        self.initializer = HeInitializer if activater == ReLU else XavierInitializer\n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        Learn a neural network classifier.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : The following forms of ndarray, shape (n_samples, n_features)\n",
    "            Features of training data\n",
    "        y : The following form of ndarray, shape (n_samples,)\n",
    "            Correct answer value of training data\n",
    "        X_val : The following forms of ndarray, shape (n_samples, n_features)\n",
    "            Features of verification data\n",
    "        y_val : The following form of ndarray, shape (n_samples,)\n",
    "            Correct value of verification data\n",
    "        \"\"\"\n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "        \n",
    "        \n",
    "        self.Conv1d = Conv1dWithStride(b_size=7, initializer=SimpleInitializer(0.01), optimizer=self.optimizer(self.lr), n_in_channels=1, n_out_channels=1, pa=3, s=2)\n",
    "        self.Conv1d.n_out = output_size_calculation(X.shape[-1], self.Conv1d.pa, self.Conv1d.b_size, self.Conv1d.s)\n",
    "        self.activation1 = self.activater()\n",
    "        self.FC2 = FC(self.Conv1d.n_out, self.n_nodes2, self.initializer(self.sigma), self.optimizer(self.lr))\n",
    "        self.activation2 = self.activater()\n",
    "        self.FC3 = FC(self.n_nodes2, self.n_output, self.initializer(self.sigma), self.optimizer(self.lr))\n",
    "        self.activation3 = Softmax()\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size, seed=i)\n",
    "            # Get batch\n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "                self.forward(mini_X_train)\n",
    "                self.backward(mini_X_train, mini_y_train)\n",
    "            \n",
    "            if self.verbose:\n",
    "                print(f\"Epoch {i+1}:\")\n",
    "                self.forward(X)\n",
    "                train_loss = self.activation3.backward(y, self.Z3)[1]\n",
    "                self.train_loss.append(train_loss)\n",
    "                print(f\"train_loss: {train_loss}\")\n",
    "            \n",
    "                if X_val is not None and y_val is not None:\n",
    "                    self.forward(X_val)\n",
    "                    val_loss = self.activation3.backward(y_val, self.Z3)[1]\n",
    "                    self.val_loss.append(val_loss)\n",
    "                    if self.verbose:\n",
    "                        print(f\"val_loss: {val_loss}\")\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Estimate using a neural network classifier.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : The following forms of ndarray, shape (n_samples, n_features)\n",
    "            sample\n",
    "        Returns\n",
    "        -------\n",
    "            The following form of ndarray, shape (n_samples, 1)\n",
    "            Estimated result\n",
    "        \"\"\"\n",
    "        self.forward(X)\n",
    "        return np.argmax(self.Z3, axis=1)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.A1 = self.Conv1d.forward(X)\n",
    "        self.A1 = self.A1.reshape(self.A1.shape[0], self.A1.shape[-1])\n",
    "        self.Z1 = self.activation1.forward(self.A1)\n",
    "        self.A2 = self.FC2.forward(self.Z1)\n",
    "        self.Z2 = self.activation2.forward(self.A2)\n",
    "        self.A3 = self.FC3.forward(self.Z2)\n",
    "        self.Z3 = self.activation3.forward(self.A3)\n",
    "    \n",
    "    def backward(self, X, Y):\n",
    "        dA3, loss = self.activation3.backward(Y)\n",
    "        dZ2 = self.FC3.backward(dA3)\n",
    "        dA2 = self.activation2.backward(dZ2)\n",
    "        dZ1 = self.FC2.backward(dA2)\n",
    "        dA1 = self.activation1.backward(dZ1)\n",
    "        dA1 = dA1[:, np.newaxis]\n",
    "        dZ0 = self.Conv1d.backward(dA1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e34ec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f61370ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e02237d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784)\n",
      "(48000,)\n",
      "(12000, 784)\n",
      "(12000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb999ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_val_one_hot = enc.transform(y_val[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "38b6be83",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCNN = ScratchCNNClassifier(verbose=True, epochs=10, optimizer=AdaGrad, activater=ReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cedf2b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "train_loss: 0.19950240251846568\n",
      "val_loss: 0.20475360745721424\n",
      "Epoch 2:\n",
      "train_loss: 0.15213026100227175\n",
      "val_loss: 0.1634210588613348\n",
      "Epoch 3:\n",
      "train_loss: 0.1256272924573344\n",
      "val_loss: 0.13810969138965368\n",
      "Epoch 4:\n",
      "train_loss: 0.11162386777805586\n",
      "val_loss: 0.12849233846239244\n",
      "Epoch 5:\n",
      "train_loss: 0.10081346023703697\n",
      "val_loss: 0.1186870153799514\n",
      "Epoch 6:\n",
      "train_loss: 0.09102931968021057\n",
      "val_loss: 0.11253712089303423\n",
      "Epoch 7:\n",
      "train_loss: 0.0852299090309255\n",
      "val_loss: 0.10905039332909999\n",
      "Epoch 8:\n",
      "train_loss: 0.07890483326110273\n",
      "val_loss: 0.10562769652786488\n",
      "Epoch 9:\n",
      "train_loss: 0.07201397907493129\n",
      "val_loss: 0.09957932784293358\n",
      "Epoch 10:\n",
      "train_loss: 0.06783803348275294\n",
      "val_loss: 0.09735316046755285\n"
     ]
    }
   ],
   "source": [
    "SCNN.fit(X_train, y_train_one_hot, X_val, y_val_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d567835d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 4 ... 0 7 5] [3 3 4 ... 0 7 5]\n",
      "[1 3 9 ... 0 1 2] [1 3 7 ... 0 1 2]\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = SCNN.predict(X_train)\n",
    "y_val_pred = SCNN.predict(X_val)\n",
    "print(y_train, y_train_pred)\n",
    "print(y_val, y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9806a493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      4721\n",
      "           1       0.98      0.99      0.99      5441\n",
      "           2       0.98      0.98      0.98      4765\n",
      "           3       0.98      0.97      0.98      4882\n",
      "           4       0.98      0.97      0.98      4635\n",
      "           5       0.98      0.98      0.98      4360\n",
      "           6       0.99      0.99      0.99      4740\n",
      "           7       0.98      0.98      0.98      5021\n",
      "           8       0.98      0.97      0.97      4646\n",
      "           9       0.96      0.97      0.97      4789\n",
      "\n",
      "    accuracy                           0.98     48000\n",
      "   macro avg       0.98      0.98      0.98     48000\n",
      "weighted avg       0.98      0.98      0.98     48000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "21b140b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(np.arange(1, SCNN.epochs+1), SCNN.train_loss, label='train')\n",
    "plt.plot(np.arange(1, SCNN.epochs+1), SCNN.val_loss, label='val')\n",
    "plt.xlabel('Epochs')\n",
    "plt.xticks(np.arange(1, SCNN.epochs+1))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9e78af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
