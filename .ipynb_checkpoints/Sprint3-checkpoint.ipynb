{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 3\n",
    "\n",
    "## Machine Learning - Scratch Linear Regression\n",
    "\n",
    "### [Problem 1] Hypothetical function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchLinearRegression():\n",
    "    \"\"\"\n",
    "    Scratch implementation of linear regression\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    num_iter : int\n",
    "      Number of iterations\n",
    "    lr : float\n",
    "      Learning rate\n",
    "    no_bias : bool\n",
    "      True if no bias term is included\n",
    "    verbose : bool\n",
    "      True to output the learning process\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    self.coef_ : The following form of ndarray, shape (n_features,)\n",
    "      Parameters\n",
    "    self.loss : The following form of ndarray, shape (self.iter,)\n",
    "      Record losses on training data\n",
    "    self.val_loss : The following form of ndarray, shape (self.iter,)\n",
    "      Record loss on validation data\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_iter, lr, no_bias, verbose):\n",
    "        # Record hyperparameters as attributes\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.no_bias = no_bias\n",
    "        self.verbose = verbose\n",
    "        # Prepare an array to record the loss\n",
    "        self.loss = np.zeros(self.iter)\n",
    "        self.val_loss = np.zeros(self.iter)\n",
    "        \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        Learn linear regression. If validation data is entered, the loss and accuracy for it are also calculated for each iteration.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : The following forms of ndarray, shape (n_samples, n_features)\n",
    "            Features of training data\n",
    "        y : The following form of ndarray, shape (n_samples,)\n",
    "            Correct answer value of training data\n",
    "        X_val : The following forms of ndarray, shape (n_samples, n_features)\n",
    "            Features of verification data\n",
    "        y_val : The following form of ndarray, shape (n_samples,)\n",
    "            Correct value of verification data\n",
    "        \"\"\"\n",
    "        n_features = X.shape[1]\n",
    "        # Prepare theta for hypotheis function\n",
    "        self.theta = np.random.rand(n_features)\n",
    "        for i in range(self.iter):\n",
    "            y_hyp = self._linear_hypothesis(X)\n",
    "            self.theta = self._gradient_descent(X, y, y_hyp)\n",
    "            self.loss[i] = self._loss_function(y_hyp, y)\n",
    "            if X_val is not None and y_val is not None:\n",
    "                y_predict = self.predict(X_val)\n",
    "                self.val_loss[i] = self._loss_function(y_predict, y_val)\n",
    "        if self.verbose:\n",
    "            #Output learning process when verbose is set to True\n",
    "            print(\"Loss: {}\".format(self.loss))\n",
    "            print(\"Val_loss: {}\".format(self.val_loss))\n",
    "        pass\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Estimate using linear regression.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : The following forms of ndarray, shape (n_samples, n_features)\n",
    "            sample\n",
    "        Returns\n",
    "        -------\n",
    "            The following form of ndarray, shape (n_samples, 1)\n",
    "            Estimated result by linear regression\n",
    "        \"\"\"\n",
    "        return X @ self.theta\n",
    "    \n",
    "    def _linear_hypothesis(self, X):\n",
    "        \"\"\"\n",
    "        Compute a linear hypothetical function\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : The following forms of ndarray, shape (n_samples, n_features)\n",
    "          Training data\n",
    "        Returns\n",
    "        -------\n",
    "          The following form of ndarray, shape (n_samples, 1)\n",
    "          Estimated result by linear hypothetical function\n",
    "        \"\"\"\n",
    "        y_hyp = np.dot(X, self.theta.T)\n",
    "        return y_hyp\n",
    "    \n",
    "    def _gradient_descent(self, X, y, y_hyp):\n",
    "        \"\"\"\n",
    "        Update new theta j in the steepest decent method\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: The following forms of ndarray, shape (n_samples, n_features)\n",
    "            Training data\n",
    "        y: The following form of ndarray, shape (n_samples,)\n",
    "            Correct answer value of training data\n",
    "        Returns\n",
    "        -------\n",
    "        \n",
    "        \"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        update_theta = self.theta - (self.lr * np.dot((y_hyp - y), X) / n_samples)\n",
    "        return update_theta\n",
    "    \n",
    "    def _loss_function(self, y_pred, y):\n",
    "        \"\"\"\n",
    "        Calculation of objective function.\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_pred : The following forms of ndarray, shape (n_samples,)\n",
    "          Estimated value\n",
    "        y : The following forms of ndarray, shape (n_samples,)\n",
    "          Correct answer value\n",
    "        Returns\n",
    "        ----------\n",
    "        loss: numpy.float\n",
    "          Result of the loss function\n",
    "        \"\"\"\n",
    "        loss = np.mean((y_pred - y) ** 2) / 2\n",
    "        return loss\n",
    "        \n",
    "\n",
    "# Outside the class\n",
    "def MSE(y_pred, y):\n",
    "    \"\"\"\n",
    "    Calculation of mean square error\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_pred : The following forms of ndarray, shape (n_samples,)\n",
    "      Estimated value\n",
    "    y : The following forms of ndarray, shape (n_samples,)\n",
    "      Correct answer value\n",
    "    Returns\n",
    "    ----------\n",
    "    mse : numpy.float\n",
    "      Mean squared error\n",
    "    \"\"\"\n",
    "    n_samples = y.shape[0]\n",
    "    mse = np.mean((y_pred - y) ** 2)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 2)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([\n",
    "    [1, 2],\n",
    "    [3, 5],\n",
    "    [5, 1],\n",
    "    [7, 4],\n",
    "    [0, 2],\n",
    "    [2, 0],\n",
    "    [4, 3]\n",
    "])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7,)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let y = 2x1 + 1x2\n",
    "y = np.array([4, 11, 11, 18, 2, 4, 11])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "slr = ScratchLinearRegression(100, 0.01, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: [2.08364014e+01 1.30597286e+01 8.21092561e+00 5.18653992e+00\n",
      " 3.29903665e+00 2.12002702e+00 1.38258878e+00 9.20404920e-01\n",
      " 6.29842786e-01 4.46326747e-01 3.29616655e-01 2.54635297e-01\n",
      " 2.05753245e-01 1.73227904e-01 1.50984779e-01 1.35235045e-01\n",
      " 1.23614185e-01 1.14645291e-01 1.07404658e-01 1.01313422e-01\n",
      " 9.60077215e-02 9.12577987e-02 8.69175852e-02 8.28932847e-02\n",
      " 7.91237928e-02 7.55684910e-02 7.21996370e-02 6.89976182e-02\n",
      " 6.59479894e-02 6.30396230e-02 6.02635517e-02 5.76122437e-02\n",
      " 5.50791469e-02 5.26584014e-02 5.03446566e-02 4.81329539e-02\n",
      " 4.60186500e-02 4.39973669e-02 4.20649566e-02 4.02174768e-02\n",
      " 3.84511734e-02 3.67624660e-02 3.51479375e-02 3.36043243e-02\n",
      " 3.21285082e-02 3.07175095e-02 2.93684802e-02 2.80786979e-02\n",
      " 2.68455601e-02 2.56665787e-02 2.45393752e-02 2.34616755e-02\n",
      " 2.24313054e-02 2.14461863e-02 2.05043309e-02 1.96038391e-02\n",
      " 1.87428944e-02 1.79197599e-02 1.71327751e-02 1.63803525e-02\n",
      " 1.56609742e-02 1.49731888e-02 1.43156091e-02 1.36869084e-02\n",
      " 1.30858184e-02 1.25111266e-02 1.19616736e-02 1.14363510e-02\n",
      " 1.09340991e-02 1.04539047e-02 9.99479899e-03 9.55585592e-03\n",
      " 9.13618999e-03 8.73495459e-03 8.35134030e-03 7.98457326e-03\n",
      " 7.63391357e-03 7.29865387e-03 6.97811781e-03 6.67165878e-03\n",
      " 6.37865856e-03 6.09852607e-03 5.83069620e-03 5.57462865e-03\n",
      " 5.32980687e-03 5.09573695e-03 4.87194672e-03 4.65798472e-03\n",
      " 4.45341932e-03 4.25783784e-03 4.07084575e-03 3.89206582e-03\n",
      " 3.72113739e-03 3.55771565e-03 3.40147093e-03 3.25208803e-03\n",
      " 3.10926560e-03 2.97271552e-03 2.84216233e-03 2.71734267e-03]\n",
      "Val_loss: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "theta = slr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.05145989, 11.11476742, 10.90078909, 17.96409661,  2.07922453,\n",
       "        3.94447073, 11.00777825])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slr_predict = slr.predict(X)\n",
    "slr_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y_pred, y):\n",
    "    \"\"\"\n",
    "    Calculation of mean square error\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_pred : The following forms of ndarray, shape (n_samples,)\n",
    "      Estimated value\n",
    "    y : The following forms of ndarray, shape (n_samples,)\n",
    "      Correct answer value\n",
    "    Returns\n",
    "    ----------\n",
    "    mse : numpy.float\n",
    "      Mean squared error\n",
    "    \"\"\"\n",
    "    n_samples = y.shape[0]\n",
    "    mse = np.mean((y_pred - y) ** 2)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005196009467132918\n"
     ]
    }
   ],
   "source": [
    "print(MSE(y, slr_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-04d00b4537ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1176\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1179\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2008\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
