{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff5a0903",
   "metadata": {},
   "source": [
    "# Sprint 10\n",
    "\n",
    "## Deep Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4946dddc",
   "metadata": {},
   "source": [
    "### [Problem 1] Classifying fully connected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cfa745e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC:\n",
    "    \"\"\"\n",
    "    Number of nodes Fully connected layer from n_nodes1 to n_nodes2\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      Number of nodes in the previous layer\n",
    "    n_nodes2 : int\n",
    "      Number of nodes in the later layer\n",
    "    initializer: instance of initialization method\n",
    "    optimizer: instance of optimization method\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.W = initializer.W(self.n_nodes1, self.n_nodes2)\n",
    "        self.B = initializer.B(self.n_nodes2)\n",
    "        self.optimizer = optimizer\n",
    "        self.HW = 0\n",
    "        self.HB = 0\n",
    "        pass\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        forward\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : The following forms of ndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : The following forms of ndarray, shape (batch_size, n_nodes2)\n",
    "            output\n",
    "        \"\"\"       \n",
    "        self.Z = X\n",
    "        self.A = X @ self.W + self.B\n",
    "        return self.A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        Backward\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : The following forms of ndarray, shape (batch_size, n_nodes2)\n",
    "            Gradient flowing from behind\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : The following forms of ndarray, shape (batch_size, n_nodes1)\n",
    "            Gradient to flow forward\n",
    "        \"\"\"\n",
    "        self.dB = np.sum(dA, axis=0)\n",
    "        self.dW = self.Z.T @ dA\n",
    "        self.dZ = dA @ self.W.T\n",
    "        self = self.optimizer.update(self)\n",
    "        return self.dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6333fa20",
   "metadata": {},
   "source": [
    "### [Problem 2] Classifying the initialization method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60c000b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInitializer:\n",
    "    \"\"\"\n",
    "    Simple initialization with Gaussian distribution\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      Standard deviation of Gaussian distribution\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        Weight initialization\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          Number of nodes in the previous layer\n",
    "        n_nodes2 : int\n",
    "          Number of nodes in the later layer\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        Bias initialization\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          Number of nodes in the later layer\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        B = self.sigma * np.random.randn(n_nodes2)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f71dbc",
   "metadata": {},
   "source": [
    "### [Problem 3] Classifying optimization methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73a02d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"\n",
    "    Stochastic gradient descent\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : Learning rate\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        Update weights and biases for a layer\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : Instance of the layer before update\n",
    "        \"\"\"\n",
    "        layer.W -= self.lr * layer.dW / len(layer.Z)\n",
    "        layer.B -= self.lr * layer.dB / len(layer.Z)\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bf3cb6",
   "metadata": {},
   "source": [
    "### [Problem 4] Classifying activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7d39ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    \n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        Z = 1 / (1 + np.exp(-self.A))\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        dA = dZ * ((1 / (1 + np.exp(-self.A))) - (1 / (1 + np.exp(-self.A))) ** 2)\n",
    "        return dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "812c2f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh:\n",
    "    \n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        Z = np.tanh(self.A)\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        dA = dZ + (1 - np.tanh(self.A) ** 2)\n",
    "        return dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "741635af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    \n",
    "    def forward(self, A):\n",
    "        Z = np.exp(A) / np.sum(np.exp(A), axis=1).reshape(-1, 1)\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, Z, y):\n",
    "        dA = Z - y\n",
    "        loss = -np.sum(y * np.log(Z)) / len(y)\n",
    "        return dA, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9ed6cc",
   "metadata": {},
   "source": [
    "### [Problem 5] ReLU class creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7c565c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    \n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        Z = np.maximum(0, A)\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        dA = dZ * np.where(self.A > 0, 1, 0)\n",
    "        return dA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79d7f74",
   "metadata": {},
   "source": [
    "### [Problem 6] Initial value of weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea25d42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XavierInitializer:\n",
    "    \n",
    "    def __init__(self, sigma):\n",
    "        pass\n",
    "    \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        self.sigma = 1 / np.sqrt(n_nodes1)\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        B = self.sigma * np.random.randn(1, n_nodes2)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c0d77e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeInitializer:\n",
    "    \n",
    "    def __init__(self, sigma):\n",
    "        pass\n",
    "    \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        self.sigma = np.sqrt(2 / n_nodes1)\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        return W\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        B = self.sigma * np.random.randn(1, n_nodes2)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5cad40",
   "metadata": {},
   "source": [
    "### [Problem 7] Optimization method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9ab5c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "    \n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, layer):\n",
    "        layer.HW += layer.dW * layer.dW\n",
    "        layer.HB += layer.dB * layer.dB\n",
    "        delta = 1e-7\n",
    "        layer.W -= self.lr * layer.dW / (np.sqrt(layer.HW) + delta) / len(layer.Z)\n",
    "        layer.B -= self.lr * layer.dB / (np.sqrt(layer.HB) + delta) / len(layer.Z)\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec22b913",
   "metadata": {},
   "source": [
    "### [Problem 8] Class Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a68d72c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    Iterator to get a mini-batch\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : The following forms of ndarray, shape (n_samples, n_features)\n",
    "      Training data\n",
    "    y : The following form of ndarray, shape (n_samples, 1)\n",
    "      Correct answer value\n",
    "    batch_size : int\n",
    "      Batch size\n",
    "    seed : int\n",
    "      NumPy random number seed\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    \n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "    \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "920c1fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchDeepNeuralNetworkClassifier():\n",
    "    \"\"\"\n",
    "    Simple three-layer neural network classifier\n",
    "    Parameters\n",
    "    ----------\n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma=0.01, n_features=784, n_nodes1=400, n_nodes2=200,\n",
    "                 n_output=10, learning_rate=0.01, epochs=10, \n",
    "                 batch_size=32, verbose=True, optimizer=SGD, initializer=HeInitializer,\n",
    "                 activater=ReLU):\n",
    "        self.verbose = verbose\n",
    "        self.sigma = sigma\n",
    "        self.n_features = n_features\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.n_output = n_output\n",
    "        self.lr = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Update\n",
    "        self.optimizer = optimizer\n",
    "        self.initializer = initializer\n",
    "        self.activater = activater\n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        Learn a neural network classifier.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : The following forms of ndarray, shape (n_samples, n_features)\n",
    "            Features of training data\n",
    "        y : The following form of ndarray, shape (n_samples,)\n",
    "            Correct answer value of training data\n",
    "        X_val : The following forms of ndarray, shape (n_samples, n_features)\n",
    "            Features of verification data\n",
    "        y_val : The following form of ndarray, shape (n_samples,)\n",
    "            Correct value of verification data\n",
    "        \"\"\"\n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "        \n",
    "        optimizer = self.optimizer(self.lr)\n",
    "        \n",
    "        self.FC1 = FC(self.n_features, self.n_nodes1, self.initializer(self.sigma), optimizer)\n",
    "        self.activation1 = self.activater()\n",
    "        self.FC2 = FC(self.n_nodes1, self.n_nodes2, self.initializer(self.sigma), optimizer)\n",
    "        self.activation2 = self.activater()\n",
    "        self.FC3 = FC(self.n_nodes2, self.n_output, self.initializer(self.sigma), optimizer)\n",
    "        self.activation3 = Softmax()\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size, seed=i)\n",
    "            # Get batch\n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "                self.forward(mini_X_train)\n",
    "                self.backward(mini_X_train, mini_y_train)\n",
    "            \n",
    "            if self.verbose:\n",
    "                print(f\"Epoch {i+1}:\")\n",
    "                self.forward(X)\n",
    "                train_loss = self.activation3.backward(self.Z3, y)[1]\n",
    "                self.train_loss.append(train_loss)\n",
    "                print(f\"train_loss: {train_loss}\")\n",
    "            \n",
    "                if X_val is not None and y_val is not None:\n",
    "                    self.forward(X_val)\n",
    "                    val_loss = self.activation3.backward(self.Z3, y_val)[1]\n",
    "                    self.val_loss.append(val_loss)\n",
    "                    if self.verbose:\n",
    "                        print(f\"val_loss: {val_loss}\")\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Estimate using a neural network classifier.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : The following forms of ndarray, shape (n_samples, n_features)\n",
    "            sample\n",
    "        Returns\n",
    "        -------\n",
    "            The following form of ndarray, shape (n_samples, 1)\n",
    "            Estimated result\n",
    "        \"\"\"\n",
    "        self.forward(X)\n",
    "        return np.argmax(self.Z3, axis=1)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.A1 = self.FC1.forward(X)\n",
    "        self.Z1 = self.activation1.forward(self.A1)\n",
    "        self.A2 = self.FC2.forward(self.Z1)\n",
    "        self.Z2 = self.activation2.forward(self.A2)\n",
    "        self.A3 = self.FC3.forward(self.Z2)\n",
    "        self.Z3 = self.activation3.forward(self.A3)\n",
    "    \n",
    "    def backward(self, X, Y):\n",
    "        dA3, loss = self.activation3.backward(self.Z3, Y)\n",
    "        dZ2 = self.FC3.backward(dA3)\n",
    "        dA2 = self.activation2.backward(dZ2)\n",
    "        dZ1 = self.FC2.backward(dA2)\n",
    "        dA1 = self.activation1.backward(dZ1)\n",
    "        dZ0 = self.FC1.backward(dA1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff05d9f",
   "metadata": {},
   "source": [
    "### [Problem 9] Learning and estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae779950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a23ca86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd2775fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd9921e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_val_one_hot = enc.transform(y_val[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0dd94d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SDNN = ScratchDeepNeuralNetworkClassifier(verbose=True, epochs=10, optimizer=AdaGrad, initializer=HeInitializer, activater=ReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce6d1813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "train_loss: 0.5042175482351622\n",
      "val_loss: 0.513192261806831\n",
      "Epoch 2:\n",
      "train_loss: 0.4010243181160156\n",
      "val_loss: 0.41041481583397876\n",
      "Epoch 3:\n",
      "train_loss: 0.3579543529199582\n",
      "val_loss: 0.36765975342195617\n",
      "Epoch 4:\n",
      "train_loss: 0.3315118786638317\n",
      "val_loss: 0.3414226549722536\n",
      "Epoch 5:\n",
      "train_loss: 0.3135046005691651\n",
      "val_loss: 0.32377371148687684\n",
      "Epoch 6:\n",
      "train_loss: 0.3000389801486477\n",
      "val_loss: 0.31052897415239267\n",
      "Epoch 7:\n",
      "train_loss: 0.2895187968854492\n",
      "val_loss: 0.300020939468969\n",
      "Epoch 8:\n",
      "train_loss: 0.2805866926426714\n",
      "val_loss: 0.291499784309799\n",
      "Epoch 9:\n",
      "train_loss: 0.273147006833077\n",
      "val_loss: 0.2839401034350941\n",
      "Epoch 10:\n",
      "train_loss: 0.26669803477757587\n",
      "val_loss: 0.2777970173537836\n"
     ]
    }
   ],
   "source": [
    "SDNN.fit(X_train, y_train_one_hot, X_val, y_val_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3b72598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 4 9 ... 0 2 6] [9 4 9 ... 0 2 6]\n",
      "[0 9 7 ... 3 8 5] [6 9 7 ... 2 8 5]\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = SDNN.predict(X_train)\n",
    "y_val_pred = SDNN.predict(X_val)\n",
    "print(y_train, y_train_pred)\n",
    "print(y_val, y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3c7dec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      4761\n",
      "           1       0.95      0.98      0.96      5453\n",
      "           2       0.93      0.91      0.92      4786\n",
      "           3       0.92      0.89      0.91      4830\n",
      "           4       0.92      0.93      0.92      4668\n",
      "           5       0.91      0.89      0.90      4287\n",
      "           6       0.94      0.95      0.95      4750\n",
      "           7       0.94      0.94      0.94      5019\n",
      "           8       0.91      0.90      0.90      4702\n",
      "           9       0.89      0.90      0.90      4744\n",
      "\n",
      "    accuracy                           0.93     48000\n",
      "   macro avg       0.93      0.93      0.93     48000\n",
      "weighted avg       0.93      0.93      0.93     48000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f7050bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      1162\n",
      "           1       0.94      0.97      0.96      1289\n",
      "           2       0.93      0.89      0.91      1172\n",
      "           3       0.92      0.89      0.91      1301\n",
      "           4       0.92      0.93      0.93      1174\n",
      "           5       0.90      0.90      0.90      1134\n",
      "           6       0.95      0.95      0.95      1168\n",
      "           7       0.93      0.94      0.93      1246\n",
      "           8       0.90      0.89      0.90      1149\n",
      "           9       0.90      0.90      0.90      1205\n",
      "\n",
      "    accuracy                           0.93     12000\n",
      "   macro avg       0.92      0.92      0.92     12000\n",
      "weighted avg       0.92      0.93      0.92     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7722bbe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(np.arange(1, SDNN.epochs+1), SDNN.train_loss, label='train')\n",
    "plt.plot(np.arange(1, SDNN.epochs+1), SDNN.val_loss, label='val')\n",
    "plt.xlabel('Epochs')\n",
    "plt.xticks(np.arange(1, SDNN.epochs+1))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
